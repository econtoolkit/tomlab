\documentclass[nofootline]{etk-presentation}
\usepackage{pstool}
\mintedwithaux %Loads the \usepackage{minted} with options for the auxilary files being moved.

\begin{document}
\title{Auto-Differentiation and Sparsity with Tomlab and Julia}
\author[Jesse Perla]{\large Jesse Perla \\ {\small \textit{University of British Columbia}}}
%	\date{May 2017}
%\date{} %Shows date and conditionally the revision.	
\maketitle
	\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{Auto-Differentiation(AD) }}
	\end{center}
\end{frame}
\begin{frame}[fragile]	\frametitle{Derivatives and Numerical Methods}
	There are two general types of algorithms for optimizers/solvers/etc.:
	\begin{enumerate}
		\item Derivative-free:
		\begin{itemize}
			\item e.g. Simplex and Nelder-Mead.  This is Matlab's \verb|fminsearch|
			\item Also, ``costly global function'' optimization and ``black box'' optimization where derivatives are not possible
			\item Avoid at all costs (though sometimes don't have a choice)
		\end{itemize}
	\bigskip
		\item Derivatives
		\begin{itemize}
			\item Pretty much every other algorithm, especially for large number of variables/constraints
			\item Including global optimization techniques (which use derivatives locally)
			\item Sometimes naive use of software is generating derivatives with finite differences without your knowledge
		\end{itemize}	
	\end{enumerate}
\bigskip
Key derivatives to calculate are:
\begin{itemize}
	\item Gradient of objective
	\item Hessian of objective (nonlinear least squares only uses gradient)
	\item Jacobian, and sometimes Lagrangian, of constraints
\end{itemize}


\end{frame}

\begin{frame}[fragile]	\frametitle{Calculating Derivatives}
How to calculate derivatives for the objective and constraints?
\begin{enumerate}
	\item Calculate by hand
	\begin{itemize}
		\item Sometimes, though not always, the most accurate and fastest option
		\item But algebra is error prone for non-trivial setups
		\item (note: many optimizers have a way to check your analytical derivatives)
	\end{itemize}
\bigskip
	\item Finite-differences:
	\begin{itemize}
		\item $\D[x_i]f(x_1,\ldots x_N) \approx \frac{f(x_1,\ldots x_i + \Delta,\ldots x_N) - f(x_1,\ldots x_i,\ldots x_N)}{\Delta}$
		\item Evaluates function at least $N$ extra times to get a gradient
		\item \# evaluations for Jacobians with $M$ constraints even worse
		\item Large $\Delta$ is numerically stable but inaccurate, small $\Delta$ is unstable
		\item \textbf{Avoid like the plague!} (and is what matlab does out of the box)
	\end{itemize}
\bigskip
	\item Auto-differentiation
	\begin{itemize}
		\item Not a form of finite-differences or numeric differentiation
		\item Essentially analytical.  Repeated use of the chain-rule
		\item Does not work for every function, but only evaluates $f(\cdot)$ once if it works---i.e. $O(1)$ not $O(N\times M)$ for $f : \R^N \to \R^M$
	\end{itemize}
\end{enumerate}
\end{frame}


\begin{frame}[fragile]	\frametitle{Auto-differentiation (adapted from Wikipedia)}
	\begin{itemize}
		\item Remember the chain rule: $\frac{dy}{dx} = \frac{dy}{dw} \frac{dw}{dx}$
		\item Consider functions composed of calculations with fundamental operations (with known analytical derivatives)
		\item For example, consider function: $f(x_1, x_2) = x_1 x_2 + \sin(x_1)$	
	$$
\begin{array}{l|l}
\text{Operations to compute value} &
\text{Operations to compute $\frac{d f(x_1,x_2)}{d x_1}$}
\\
\hline
w_1 = x_1 &
\frac{d w_1}{d x_1} = 1 \text{ (seed)}\\
w_2 = x_2 &
\frac{d  w_2}{d x_1} = 0 \text{ (seed)}
\\
w_3 = w_1 \cdot w_2 &
\frac{d  w_3}{d x_1} = w_2 \cdot \frac{d  w_1}{d x_1} + w_1 \cdot \frac{d  w_2}{d x_1}
\\
w_4 = \sin w_1 &
\frac{d  w_4}{d x_1} = \cos w_1 \cdot \frac{d  w_1}{d x_1}
\\
w_5 = w_3 + w_4 &
\frac{d  w_5}{d x_1} = \frac{d  w_3}{d x_1} + \frac{d  w_4}{d x_1}
\end{array}
$$
\item Generalizes to multiple variables.  AD takes source code and generates the derivatives at the same time it calculates the function value.%  Crucially, it at the same time (i.e. cost doesn't scale with \# vars)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{Auto-differentiation With Dual Numbers }
	\begin{itemize}
		\item Augment number with a second part (like complex numbers)
		\begin{itemize}
			\item $x \to x + x' \epsilon$ where $\epsilon^2 = 0$
			\item Can represent as a tuple, $\left<x, x'\right>$			
		\end{itemize}
		\item General rule for $g(x,y)$: $g(\left<x,x'\right>,\left<y,y'\right>) = \left<g(x,y),\D[x]g(x,y)x' + \D[y]g(x,y)y' \right>$
		\begin{itemize}
		\item i.e., the chain rule for a total derivative
		\item Note: concurrently calculates function and derivatives
		\end{itemize}
		\item Example rules:
		\begin{align*}
		x + y \to \left<x,x'\right> + \left<y,y'\right> &= \left<x + y,\underbrace{x' + y'}_{\D(x + y) = \D x + \D y}\right>\\
		x y \to \left<x,x'\right> \times \left<y,y'\right> &= \left<x y,\underbrace{x'y + y'x}_{\D(x y) = y \D x + x \D y y}\right>\\
		\exp(x) \to \exp(\left<x, x'\right>) &= \left<\exp(x),\underbrace{x'\exp(x)}_{\D(\exp(x)) = \exp(x)\D x} \right>
		\end{align*}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{Seeding and Operator Overloading}
	\begin{itemize}
		\item Hence, an arbitrary sequence of ``basic'' operations can be composed
		\item How to start?  Need to start with a dual number
		\begin{itemize}
			\item $\left<x,1\right>$: note the derivative wrt itself is $1$
			\smallskip
			\item Then can apply whatever sequence of operations you want
			\item Constants are implemented as $\left<c,0\right>$, i.e. $\D c = 0$
		\end{itemize}
		\item Operator overloading: version of basic operations for dual numbers
	\end{itemize}
\begin{minted}[fontsize=\footnotesize]{matlab}
%matlab with fmad libary
x = fmad(x_val, 1); %Seeds to create a dual, since dx/dx = 1
y = exp(x); %Actually using the exp for dual numbers
z = x + y; %Actually using the + for dual numbers.
function out = f(x)
	out = sin(x); %no problem for dual numbers if sin is defined
end
q = f(y); %q still has the derivative and value calculated
\end{minted}

\end{frame}

\begin{frame}[fragile]	\frametitle{One of the Julia Packages}
\begin{minted}[fontsize=\footnotesize]{julia}
#Auto-differentiation with ForwardDiff in Julia
using ForwardDiff
h(x) = sin(x[1]) + x[1] * x[2] + sinh(x[1] * x[2]) #multivariate.
x = [1.4 2.2]
ForwardDiff.gradient(h,x) #uses AD, seeds from x

#Or, can use complicated functions of many variables
f(x) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);
g = (x) -> ForwardDiff.gradient(f, x); #New gradient function
x2 = rand(20)
g(x2) #gradient at a random 20 dim point
ForwardDiff.hessian(f,x2) #Or the hessian

#Practical note: for high dimensions(N > 100), use Reverse-Mode AD with sparsity
\end{minted}
\end{frame}
		

\begin{frame}[fragile]	\frametitle{Implementations of AD}
	\begin{itemize}
		\item A field unto itself.  Do not implement directly
		\item Implementation is language dependent.  Several approaches:
		\begin{itemize}
			\item \textit{Source code transformation:} utility (outside of the language itself) reads in the code for your function, and generates new source
			\item \textit{Operator Overloading:} Writes rules for dual-numbers (or equivalent).  Can be magical, or can be infuriating
			\item \textit{Reverse-Mode AD:} A more complicated approach required for big problems.  Can't do easily with operator overloading
		\end{itemize}
		\item Implementation depends on the language:
		\begin{itemize}
			\item \textit{Fortran:} usually needs SCT.  Many choices: e.g. \url{http://tapenade.inria.fr:8080/tapenade/index.jsp}
			\item \textit{Python:} \url{https://github.com/LowinData/pyautodiff} and \url{https://pythonhosted.org/algopy/}
			\item \textit{Matlab:} open source SCT (e.g. AdiMat) not very good.  Use Tomlab/MAD instead, coupled with the Tomlab optimizer
			\item \textit{Julia:} ForwardDiff, ReverseDiff, ReverseDiffSparse (used in JuMP)
		\end{itemize}
	\end{itemize}
\end{frame}

	\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{Sparsity}}
	\end{center}
\end{frame}

\begin{frame}[fragile]	\frametitle{Sparse Matrices and Methods}
	\begin{itemize}
		\item Many algorithms are specialized for matrices (or Jacobians or Hessians) with many $0$s---e.g. Gaussian elimination
		\item  Only store non-zero values, but $0 \neq 0.0$ for optimizers
		\item Not (usually) for storage, but rather specialized algorithms
		\item For Jacobians and Hessians, can solve enormous (e.g. hundreds of thousands or millions) of variable systems
		\begin{itemize}
			\item But the more non-zeros, the more likely dense methods are preferable.
		\end{itemize}

				\item For example, $f: \R^N \to \R^N$ with $f(x) = \sqrt{x}$ point-wise
				\begin{itemize}
					\item Jacobian has $N$ non-zeros, while dense has $N^2$
					\item Optimizers/solvers can use this to step in the right direction
					\item Auto-differentiation will figure out the sparsity pattern of derivatives---i.e., which values are always $0$ for all inputs
				\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[fragile] \frametitle{Sparse Matrices in Matlab}
	\begin{minted}[fontsize=\footnotesize]{matlab}
%First, can convert dense matrix, and it drops the 0's.
X = [1.0 0   0;
     2.0 1.0 0];
S = sparse(X)
%S =
%(1,1)        1
%(2,1)        2
%(2,2)        1

%Or can take lists of indices and values,
x_indices = [1; 2; 2];
y_indices = [1; 1; 2];
values = [1; 2; 1];
S2 = sparse(x_indices, y_indices, values)

%Or can preallocate and just reference in loops/etc.
S3 = sparse(0,3);
S3(1,1) = 1;
S3(2,1) = 2;
S3(2,2) = 1;
	\end{minted}
\end{frame}

\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{Tomlab Examples}}
	\end{center}
\end{frame}

\begin{frame}[fragile]	\frametitle{What is in Tomlab?}
	\begin{itemize}
		\item Sadly, the Operations Research community keeps the best implementations closed-source
		\item Collection of sparse/dense linear/nonlinear local/global constrained/unconstrained continuous/mixed-integer optimizers
		\item Nonlinear methods have built in auto-differentiation
		\item Repackages and resells state-of-the-art commercial products, and adds a few of its own (which tend to be high quality)
		\item Several methods to solve the same type of problem, because you never know which one will work best.  Easy to swap
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{What Types of Problems?}
	See \url{http://tomopt.com/docs/TOMLAB_QUICKGUIDE.pdf}. 
	\begin{itemize}
		\item Programming = Optimizer in OR
		\item Linear Programming (LP) and Mixed-Integer LP (MILP)
		\item Constrained Nonlinear Programming (NLP)
		\item Unconstrained Global Optimization (glb)
		\item Linear Least Squares (LLS)
		\item Nonlinear Least Squares (NLLS)
		\item Solving systems of equations generally uses NLLS
		\item \ldots and many others (semi-definite, quadratic, etc.)
	\end{itemize}
\medskip
	Most have sparse vs. dense algorithms, and constrained vs. unconstrained
	\begin{itemize}
		\item Read docs to find best fit for your particular problem
		\item Always use appropriate constraints (none, box-bounded, linear, etc.)
		\item For borderline sparse problems, sometimes dense works better
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{Some Packages}
	See \url{http://tomopt.com/tomlab/products/}
	\begin{itemize}
		\item Stanford 
		Systems Optimization Laboratory (SOL):\\SNOPT, NPSOL, NLSSOL, LSSOL\ldots
		\item Knitro.  Good for big problems, and complementarity conditions
		\item MAD (auto-differentiation)
		\item LGO and CGO (global optimizers, costly and otherwise)
%		\item For a given problem type, tomlab will list available algorithms
	\end{itemize}
After installing tomlab, open up matlab and type \verb!tomRun! to get a list of all licensed (and recommended) solvers by problem type
\end{frame}
%
%\begin{frame}[fragile]	\frametitle{Setting up Tomlab}
%	\begin{enumerate}
%		\item Use the UBC Matlab license
%		\begin{itemize}
%			\item If you aren't sure what you have, open matlab, type 'license' and check the nubmer is '924490'.  Otherwise, follow department/ubc instructions
%			\item UBC Economics can download \url{http://jesseperla.com/tomlab/tomlab.lic}
%		\end{itemize}
%		\item Download Tomlab from the site or 
%		\begin{itemize}
%			\item \url{http://tomopt.com/dist/tomlab-win64-setup.exe}
%			\item or \url{http://tomopt.com/dist/tomlab-osx64-clang-setup.dmg}
%		\end{itemize}
%		\item Run to install it
%		\item Put license file goes in the root of the main tomlab directory (i.e., the one with the \verb!startup.m! file)
%		\item You now have two choices:
%		\begin{itemize}
%			\item Whenever you want to use it, run the \verb!startup.m! script in tomlab
%			\item Or, put the tomlab directory in your matlab path (with "Set Path" menu) and it runs on its own when starting matlab
%		\end{itemize}
%	\item Finally, Tomlab replaces the \verb!fmincon!, \verb!fsolve! etc. in matlab
%	\begin{itemize}
%		\item Avoid by deleting/renaming files in the \verb!/optim! folder after installation
%	\end{itemize}
%	\end{enumerate}
%\end{frame}

\begin{frame}[fragile]	\frametitle{Linear Least Squares (i.e. Regression)}

	\begin{align*}
	\min_x &\frac{1}{2}\norm{C x - d}_2\\
	\st & x_L \leq x \leq x_U\\
	& b_L \leq A x \leq b_U
	\end{align*}
	
	\begin{itemize}
		\item Little benefit over stata until problems get large or sparse
		\item Though if there are linear constraints, $A$, may be helpful
		\item Major benefit for large, sparse $C$
		\item See ``Section 11. LLS Problem'' in \url{http://tomopt.com/docs/TOMLAB_QUICKGUIDE.pdf}
		\item Matlab also has a built in sparse linear least squares solver
	\end{itemize}
\end{frame}


\begin{frame}[fragile]	\frametitle{Example: Two-way fixed Effect}
	\begin{itemize}
		\item 	Use student, $i$, and instructor, $j$ fixed effects with observables
			$$
		\text{grade}_{ij} = \text{observables}_{ij} + \text{student}_i + \text{instuctor}_j + \epsilon_{ij}
		$$
		\item $300$K observations for $36$K students and $945$ instructors
		\begin{itemize}
			\item $\approx 37$K variables, \textbf{but only $2$ non-zero} (plus observables)
		\end{itemize}
		\item Took about a day to solve in Stata
		\item See \verb!teacher_student_fixed_effect.m! example for generating sparse matrix.  Given \verb!id1! student id, and \verb!id1! instructor id.  Key code:
	\end{itemize}
\begin{minted}[fontsize=\footnotesize]{matlab}
%Preallocate a sparse matrix
%Total number of observables with indicators for the two types.
X = sparse(N_observations, N_observables + N_students + N_teachers); 

%Filling in indicators for the matches
for i=1:N_observations
X(i, N_observables + id1(i)) = 1; %set student indicator
X(i, N_observables + N_students + id2(i)) = 1; %sets instructor indicator
end
\end{minted}
\end{frame}

\begin{frame}[fragile]	\frametitle{Solving LLS in Tomlab}
	\begin{itemize}
		\item Given $X$ and $y$ such that $\min_\beta\norm{X \beta - y}_2$
		\item Ensure $X$ loaded sparse, with each row having 2 indicators
	\end{itemize}
\begin{minted}[fontsize=\footnotesize]{matlab}
%linear least squares, can pass in sparse matrices or use dense
help llsAssign %Can see options, if you wish.  Or use manual

% tomlab convention, call XXXAssign for problem type XXX
Prob = llsAssign(X, y, [], [], 'LLS Example'); 

%Can change settings.  See tomlab documentation
Prob.optParam.MaxIter = 5000; %optional, increase iterations
Prob.PriLevOpt  = 1; %optional, gives more information if higher

%Tomlab convention: tomRun, passing in the algorithm type and problem
%Takes about 10-20 seconds to run, instead of a day.  Not even tweaked
Result = tomRun('Tlsqr', Prob); %intended for sparse unconstrained LLS
beta = Result.x_k;

%Tried alternative methods.  Easy to swap
%Result = tomRun('snopt', Prob); %Tlsqr works much better here
\end{minted}

\end{frame}
	
\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{Constrained Optimization }}
	\end{center}
\end{frame}

\begin{frame}[fragile]	\frametitle{Nonlinear Programming (NLP)}
Given $f : \R^N \to \R$ and $c : \R^N \to \R^M$
	\begin{align*}
		\min_x &\set{f(x)}\\
		\st & x_L \leq x \leq x_U\\
		& b_L \leq A x \leq b_U\\
		& c_L \leq c(x) \leq c_U
	\end{align*}
	
	\begin{itemize}
		\item See ``Section 7. NLP Problem'' in \url{http://tomopt.com/docs/TOMLAB_QUICKGUIDE.pdf}
		\item Can solve large problems in general with dense solvers (e.g. tens, hundreds, thousands of variables depending on structure)
		\item Can solve enormous problems if Hessian of $f(x)$, Jacobian of $c(x)$ sparse (e.g. hundreds of thousands or millions of variables)
		\item If constraints are bounds, use $x_L, x_U$.  If linear, use $A$.  Equality set $b_L(m) = b_U(m)$ where appropriate.  No bounds, leave unconstrained 
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{Example: Porfolio Choice under Rational Inattention}
	\begin{itemize}
		\item Entropy constraint, $\kappa$ and signal variances, $\sigma_n$, weights $\alpha_n$
		\item Choose precision $x_n$ 
\begin{align*}
\min_{\set{x_n}}&\sum_{n=1}^N \alpha_n^2 x_n^2\\
\st & \frac{1}{2}\sum_{n=1}^{N}\left(\log\sigma^2_n -  \log x^2_n\right) \leq \kappa\\
& 0 < x_n < \infinity
\end{align*}
		\item Generate some $\set{\alpha_n,\sigma_n}$ and solve
		\item How large for $N$?  Using \verb!fminsearch! naively, got to $N\approx 30$.  Sample code I give you solves with $N = 100,000$ in $\approx$ 20 seconds
		\item Since the hessian is sparse, could potentially use specialized methods (but didn't even bother to play with that, just using AD)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{Solving in Tomlab (with Anonymous Functions)}
\begin{minted}[fontsize=\footnotesize]{matlab}
%...define kappa, alpha vector of length N, sigma vector of length n...
objective = @(x) sum((x.^2).*(alpha.^2)); %Objective
constraint = @(x) (1/2)*sum( log(sigma.^2) - log(x.^2) ); %Constraint

%Bounds on x, and initial guess
x_L = 1E-10 * ones(N,1); %Bounding a little above 0 since it takes logs.
x_U = inf(N,1); %Upper bounds for x.
x_0 = 1.1*ones(N,1); %Some initial conditions

%Generate problem.  Use `help conAssign' to see arguments, or use manual
madinitglobals; %Need to run for auto-differentiation to work.
Prob = conAssign(objective, [], [], [], x_L, x_U, 'Portfolio example',...
   x_0, [], [], [], [], [], constraint, [], [], [], kappa, kappa);
Prob.ADObj = 1; % Gradient with AD. ADObj = -1 for Hessian
Prob.ADCons = 1; % Jacobian with AD. ADCons = -1 for constraint Lagrangian 

%Run type
Result = tomRun('knitro', Prob); %Choose algorithm. See tomlab for options
x_optimal = Result.x_k;

%Result = tomRun('npsol', Prob, 1) %Could try another algorithm

\end{minted}
\end{frame}

	
\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{Systems of Equations and NLLS}}
	\end{center}
\end{frame}

\begin{frame}[fragile]	\frametitle{Nonlinear Least Squares (NLLS)}
	Given residual $r : \R^N \to \R^M$ and $c : \R^N \to \R^P$
	\begin{align*}
		\min_x &\set{\frac{1}{2}r(x)^T r(x)}\\
		\st & x_L \leq x \leq x_U\\
		& b_L \leq A x \leq b_U\\
		& c_L \leq c(x) \leq c_U
	\end{align*}
	
	Also for solving system of equations (potentially with inequalities):
	\begin{align*}
		r(x) = \mathbf{0}
	\end{align*}
	\begin{itemize}
		\item See ``Section 13. NLLS Problem'' in \url{http://tomopt.com/docs/TOMLAB_QUICKGUIDE.pdf}
		\item Can solve very large problems, with/without constraints
%		\item No Hessian information is used in algorithms, so just gradient/jacobian.
%		\item If constraints are bounds, use $x_L, x_U$.  If linear, use $A$.  Equality set $b_L(m) = b_U(m)$ where appropriate.  No bounds, leave unconstrained 
	\end{itemize}
\end{frame}

\begin{frame}[fragile]	\frametitle{Solving NLLS}
	\begin{minted}[fontsize=\footnotesize]{matlab}
%Residual
r = @(x) x.^2 - [2; 1];	
x_0 = [5; 10];
%Create object
Prob = clsAssign(r, [], [], [], [], 'NLLS example', x_0, zeros(2,1),[]);
Prob.ADObj = 1; % Use AD

%Solve it.
Result = tomRun('nlssol', Prob, 1);
	\end{minted}
\end{frame}	
\begin{frame}\frametitle{}
		\bigskip
		\bigskip
		\bigskip	
		\begin{center}
			{\huge \emphcolor{Julia Examples}}
		\end{center}
\end{frame}

\begin{frame}[fragile]	\frametitle{Auto-differentiation (Forward)}
		\begin{minted}[fontsize=\footnotesize]{julia}
#Auto-differentiation with ForwardDiff in Julia
using ForwardDiff
h(x) = sin(x[1]) + x[1] * x[2] + sinh(x[1] * x[2]) #multivariate.
x = [1.4 2.2]
ForwardDiff.gradient(h,x) #uses AD, seeds from x

#Or, can use complicated functions, 
f(x) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);
g = (x) -> ForwardDiff.gradient(f, x); #New gradient function
x2 = rand(20)
g(x2) #gradient at a random 20 dim point
ForwardDiff.hessian(f,x2) #Or the hessian

#See https://github.com/JuliaDiff/ReverseDiff.jl
\end{minted}
\end{frame}	

\begin{frame}[fragile]	\frametitle{Optimization}
	\begin{align*}
	\min_{x,y}&\set{(1-x)^2 + 100(y-x^2)^2}\\
	\st & x + y = 10
	\end{align*}
		\begin{minted}[fontsize=\footnotesize]{julia}	
using JuMP,Ipopt
m = Model(solver = IpoptSolver())
@variable(m, x, start = 0.0)
@variable(m, y, start = 0.0)

@NLobjective(m, Min, (1-x)^2 + 100(y-x^2)^2)

solve(m)
println("x = ", getvalue(x), " y = ", getvalue(y))

# adding a (linear) constraint
@constraint(m, x + y == 10)
solve(m)
println("x = ", getvalue(x), " y = ", getvalue(y))
	\end{minted}
\end{frame}	

\begin{frame}[fragile]	\frametitle{Complicated Function with AD}
	\begin{align*}
	\max_{x\in\R^2}&\set{x(1) + x(2)}\\
	\st & \sqrt{x(1)^2 + x(2)^2} \leq 1
	\end{align*}
	\begin{minted}[fontsize=\footnotesize]{julia}	
using JuMP, Ipopt
#Can auto-differentiate complicated functions with embedded iterations
function squareroot(x) #pretending we don't know sqrt()
	z = x # Initial starting point for Newton's method
	while abs(z*z - x) > 1e-13
		z = z - (z*z-x)/(2z)
	end
	return z
end
m = Model(solver = IpoptSolver())
JuMP.register(m,:squareroot, 1, squareroot, autodiff=true) # For user defined complicated functions
@variable(m, x[1:2], start=0.5)
@objective(m, Max, sum(x))
@NLconstraint(m, squareroot(x[1]^2+x[2]^2) <= 1)
solve(m)
	\end{minted}
\end{frame}	

\begin{frame}[fragile]	\frametitle{Solving Functional Equations}
	\begin{itemize}
\item	One important use of this is solving functional equations of the form
	$$\Phi(f) = \mathbf{0}$$
	\begin{itemize}
		\item Where $f : \R^N \to \R^M$ and $\Phi$ is an operator $\Phi : \C(\R^N) \to \R^P$
		\item Could include differential equations, difference equations, etc.
	\end{itemize}
\item To solve, can approximate $f$ with a basis.  Collocation methods, etc.
\begin{itemize}
	\item e.g. $f(x) \approx \sum_{q=1}^{Q}d_q P_q(x)$
	\item Where $P_q(x)$ is a polynomial/spline/finite-element basis
	\item $d_q$ are the unknown coefficients to solve for
\end{itemize}
\item Then, problem is to find the coefficients
$$
\min_{d} \set{\frac{1}{2}\Phi(d)^T \Phi(d)}
$$
\item Since for fixed $x_n$ nodes, can usually evaluate $P_q$ through linear algebra can use AD on $\Phi(d)$
\item Note: if $\Phi(d)$ is a linear operator (e.g. linear PDEs) can use sparse LLS.  How huge numerical PDEs with millions of points are solved.
\end{itemize}
\end{frame}		
\begin{frame}\frametitle{Example: Joint HJBE and KFE}
	For example, solving a problem like
	\begin{align*}
	r v(z) &= \pi(z) + \mu v'(z) + \frac{\sigma^2}{2}v''(z)\\
	\intertext{With the KFE}
	0 &= -\mu f'(z) + \frac{\sigma^2}{2}f''(z) + \text{stuff}
	\intertext{With boundary values, integral constraints, etc.}
	1 &= \int f(z)\diff z
	\end{align*}
	Approach (though in this case, since linear, use finite-differences):
	\begin{itemize}
		\item Use chebyshev basis for $v(z)$ and $f(z)$
		\item Define a system of equations in coefficients. Naively stack
		\item Rely on auto-differention to find jacobians of big system
		\item Throw a commerical solver at it supporting big sparse systems
	\end{itemize}
	
\end{frame}
\appendixtitles
\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{Additional Information and Hints }}
	\end{center}
\end{frame}
\begin{frame}\frametitle{}
	\bigskip
	\bigskip
	\bigskip	
	\begin{center}
		{\huge \emphcolor{AD with Tomlab }}
	\end{center}
 \end{frame}

\begin{frame}[fragile] \frametitle{Using AD Directly in Tomlab}
	\begin{itemize}
	\item Keep in mind that optimizers/solvers in Tomlab do this automatically
	\item But if having trouble with optimizer calls, can test function separately
	\end{itemize}
\begin{minted}[fontsize=\footnotesize]{matlab}
%Example function.  Also works fine with separate files/function defs
f = @(x) 3*x + exp(x);

%Evaluating function
x_val = 2.1;
f(x_val)

%Evaluating with derivative at x_val
x = fmad(x_val, 1); %Seed, since dx/dx = 1
f_val = f(x)

%Extract (both calculated at same time)
getvalue(f_val)
getderivs(f_val)
\end{minted}

\end{frame}

\begin{frame}[fragile]	\frametitle{Black Magic? Is it Always so Easy?}
	\begin{itemize}
		\item Auto-differentiation works seamlessly for functions composed of an arbitrarily complicated graph of simple functions
		\begin{itemize}
			\item Just need analytical derivatives for the lowest-level functions
			\item Functions of vector and matrices are no problem at all.  In fact, the field was designed for large numbers of variables/constraints and sparsity
		\end{itemize}
	\bigskip
		\item Can you call other functions (with operator overloading)?
		\begin{itemize}
			\item Depends on how they were written.  Often no problem at all
			\item If the functions assume arguments are numbers, there can be problems
			\item Sometimes can fix the underlying code to make more generic
		\end{itemize}
	\bigskip
		\item Verboten: Iterations and fixed-points \textit{within a function}
		\begin{itemize}
			\item e.g. it can't differentiate a nested optimization step within a function
			\item However, many algorithms can be re-written without nesting (e.g. nested fixed-point vs. MPEC for discrete-choice estimation)
			\item Possible that simulation could be embedded (e.g. mixed-logit) but have never tried it
		\end{itemize}
	\end{itemize}
\end{frame}	

\begin{frame}[fragile]	\frametitle{Keep Functions Generic}
	\begin{itemize}
		\item Remember, MAD replaces arguments with things that look like variables.  Keep everything generic, don't overwrite with other types
		\item Some internal matlab functions do this sort of thing
		\item Sometimes can copy/paste others sourcecode and tweak
	\end{itemize}

\begin{minted}[fontsize=\footnotesize]{matlab}
madinitglobals; %Need to run for auto-differentiation to work
x_val = [2.1;3.0];
x = fmad(x_val, eye(2,2)); %Seeds with derivatives

%Extract (both calculated at same time)
f_val = f_func(x)

function y = f_func(x)
  y = x.^2; %This leaves x, y generic
  %x = 1; %Don't do this!!!!!!
  %y = zeros(1,1) %Don't do this!!!!!
  %y(1) = x.^2; %indexing is fine (as long as you do not preallocate)
  %One trick is to allocate as something like: y = x, then index
end
\end{minted}	

\end{frame}

\begin{frame}[fragile]	\frametitle{Missing Function (with Analytical Derivative)}
\begin{itemize}
	\item See MAD manual, \url{http://tomopt.com/docs/TOMLAB_MAD.pdf}
	\item Section: \verb!"Adding Functions to the fmad Class"!
	\item See extensions in in \url{https://github.com/econtoolkit/tomlab/MAD}
	\item Example, \verb!normcdf! isn't there, could add something like:
\end{itemize}

\begin{minted}[fontsize=\footnotesize]{matlab}
%Add to the appropriate location in tomlab
%This should work for vectors/matrices since using .*
%This has not been sufficiently tested!
function y=normcdf(x)
	y = x; %Needs to copy		
	y.value= normcdf(x.value); %Evaluate given double 
	y.deriv = normpdf(x.value) .* x.deriv; %Note chain rule
end
\end{minted}
\end{frame}

\begin{frame}[fragile]	\frametitle{Using Tomlab External Functions and Fixed Parameters}
	
\begin{minted}[fontsize=\footnotesize]{matlab}
%Alternatively, the objective/constraint can be in separate files
%Assumption is that vectors alpha/sigma/kappa attached to problem

%File: portfolio_objective.m
function f = portfolio_objective(x, Prob)
f = sum((x.^2).*(Prob.alpha .^2));
end

%File: portfolio_constraint.m
function c = portfolio_constraint(x, Prob)
	c = (1/2)*sum( log(Prob.sigma.^2) - log(x.^2) ) - Prob.kappa;
end
\end{minted}	
\end{frame}	

\begin{frame}[fragile]	\frametitle{Calling with External Functions}
\begin{minted}[fontsize=\footnotesize]{matlab}
%Changed to have c(x) = 0 for the constraint since in c(x)
Prob = conAssign(@portfolio_objective, [], [], [], x_L, x_U, 'Example',...
x_0, [], [], [], [], [], @portfolio_constraint, [], [], [], 0, 0);

%Put any constants into the Prob, available in the function
%Can throw anything you want only Prob (e.g. vectors, cells, etc.)
Prob.alpha = alpha;
Prob.sigma = sigma;
Prob.kappa = kappa;

%Setup AD
Prob.ADObj = 1; % Gradient with AD. ADObj = -1 for Hessian
Prob.ADCons = 1; % Jacobian with AD. ADCons = -1 for constraint Lagrangian 

%Run the optimizer
Result = tomRun('knitro', Prob); %The last 	
\end{minted}	
\end{frame}	
%
%\begin{frame}\frametitle{}
%	\bigskip
%	\bigskip
%	\bigskip	
%	\begin{center}
%		{\huge \emphcolor{Documentation and Examples}}
%	\end{center}
%\end{frame}
%
%\begin{frame}[fragile]	\frametitle{Licenses}
%UBC Economics has purchased site licenses for the following products:
%\begin{itemize}
%	\item Base: \url{http://tomopt.com/tomlab/products/base/}
%	\item SOL: \url{http://tomopt.com/tomlab/products/sol/}
%	\item KNITRO: \url{http://tomopt.com/tomlab/products/knitro/}
%	\item LGO: \url{http://tomopt.com/tomlab/products/lgo/}
%	\item CGO: \url{http://tomopt.com/tomlab/products/cgo/}
%	\item MAD: \url{http://tomopt.com/tomlab/products/mad/}
%\end{itemize}
%If you have a problem type not covered by these solvers, tomlab is willing to let you try out additional solvers before adding them to a site (or individual) license.
%\end{frame}	
%
%\begin{frame}[fragile]	\frametitle{General Tomlab Documentation}
%Tomlab has excellent examples and documentation:
%	\begin{itemize}
%		\item Manuals: \url{http://tomopt.com/tomlab/download/manuals.php}
%		\item In particular, the Quickguide tells you how to get started with most problems:  \url{http://tomopt.com/docs/TOMLAB_QUICKGUIDE.pdf}
%		\item For more details, see \url{http://tomopt.com/docs/TOMLAB.pdf}
%		\item Finally, when tweaking with a product, see the specific guides
%		\item  For example, \url{http://tomopt.com/docs/TOMLAB_SOL.pdf} has every error code and option for the algorithms specific to the SOL solvers.
%	\end{itemize}	
%\end{frame}	
%
%\begin{frame}[fragile]	\frametitle{Tomlab Examples}
%	After installation, look inside of the main tomlab directory.
%	\begin{itemize}
%		\item 	Many of the examples are embedded in the \url{http://tomopt.com/docs/TOMLAB_QUICKGUIDE.pdf} and \url{http://tomopt.com/docs/TOMLAB.pdf}
%		\item The examples used in the quickguide are installed in tomlab at \verb!quickguide/! directory
%		\item Additionally, after installing tomlab look at \verb!examples! to see many test and example files.
%		\item See \verb!Contents.m! in both directories for a list of examples
%	\end{itemize}
%\end{frame}	
%	
%
%\begin{frame}[fragile]	\frametitle{These Slides, Examples, Etc.}
%See \url{https://github.com/econtoolkit/tomlab/tutorial}
%	\begin{itemize}
%			\item \verb!teacher_student_fixed_effect.m!: contains LLS example, including reading raw data and generating sparse matrix.  Raw data is in \verb!student_teacher_raw.mat!, and it  generates sparse data in \verb!teacher_student_data.mat!
%			\item \verb!portfolio_choice.m!: Includes all sorts of variations on the NLP problem discussed.  For the external functions, it calls \verb!portfolio_constraint.m! and \verb!portfolio_objective.m!
%	\end{itemize}
%	
%\end{frame}	


\end{document}