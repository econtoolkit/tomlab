{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":Optimal"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.2, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        2\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        1\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        1\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 -1.0000000e+000 0.00e+000 2.07e-001  -1.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 -1.4100714e+000 0.00e+000 5.48e-002  -1.7 3.94e-001    -  1.00e+000 7.36e-001f  1\n",
      "   2 -1.4113851e+000 0.00e+000 2.83e-008  -2.5 9.29e-004    -  1.00e+000 1.00e+000f  1\n",
      "   3 -1.4140632e+000 0.00e+000 1.50e-009  -3.8 1.89e-003    -  1.00e+000 1.00e+000f  1\n",
      "   4 -1.4142117e+000 0.00e+000 1.84e-011  -5.7 1.05e-004    -  1.00e+000 1.00e+000f  1\n",
      "   5 -1.4142136e+000 0.00e+000 8.23e-009  -8.6 1.30e-006    -  1.00e+000 1.00e+000f  1\n",
      "\n",
      "Number of Iterations....: 5\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............: -1.4142135740093271e+000  -1.4142135740093271e+000\n",
      "Dual infeasibility......:  8.2280586788385790e-009   8.2280586788385790e-009\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  2.5059035815063646e-009   2.5059035815063646e-009\n",
      "Overall NLP error.......:  8.2280586788385790e-009   8.2280586788385790e-009\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 6\n",
      "Number of objective gradient evaluations             = 6\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 6\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 6\n",
      "Number of Lagrangian Hessian evaluations             = 5\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.005\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    }
   ],
   "source": [
    "using JuMP, Ipopt\n",
    "# Solve constrained optimization \n",
    "# max( x[1] + x[2] )\n",
    "# st sqrt(x[1]^2 + x[2]^2) <= 1\n",
    "\n",
    "#Can even auto-differenitate complicated functions with embedded iterations\n",
    "function squareroot(x) #pretending we don't know sqrt()\n",
    "    z = x # Initial starting point for Newtonâ€™s method\n",
    "    while abs(z*z - x) > 1e-13\n",
    "        z = z - (z*z-x)/(2z)\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "m = Model(solver = IpoptSolver())\n",
    "JuMP.register(m,:squareroot, 1, squareroot, autodiff=true) # For user defined complicated functions\n",
    "\n",
    "\n",
    "@variable(m, x[1:2], start=0.5)\n",
    "@objective(m, Max, sum(x))\n",
    "@NLconstraint(m, squareroot(x[1]^2+x[2]^2) <= 1)\n",
    "solve(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.2, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.0000000e+000 0.00e+000 2.00e+000  -1.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 9.5312500e-001 0.00e+000 1.25e+001  -1.0 1.00e+000    -  1.00e+000 2.50e-001f  3\n",
      "   2 4.8320569e-001 0.00e+000 1.01e+000  -1.0 9.03e-002    -  1.00e+000 1.00e+000f  1\n",
      "   3 4.5708829e-001 0.00e+000 9.53e+000  -1.0 4.29e-001    -  1.00e+000 5.00e-001f  2\n",
      "   4 1.8894205e-001 0.00e+000 4.15e-001  -1.0 9.51e-002    -  1.00e+000 1.00e+000f  1\n",
      "   5 1.3918726e-001 0.00e+000 6.51e+000  -1.7 3.49e-001    -  1.00e+000 5.00e-001f  2\n",
      "   6 5.4940990e-002 0.00e+000 4.51e-001  -1.7 9.29e-002    -  1.00e+000 1.00e+000f  1\n",
      "   7 2.9144630e-002 0.00e+000 2.27e+000  -1.7 2.49e-001    -  1.00e+000 5.00e-001f  2\n",
      "   8 9.8586451e-003 0.00e+000 1.15e+000  -1.7 1.10e-001    -  1.00e+000 1.00e+000f  1\n",
      "   9 2.3237475e-003 0.00e+000 1.00e+000  -1.7 1.00e-001    -  1.00e+000 1.00e+000f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10 2.3797236e-004 0.00e+000 2.19e-001  -1.7 5.09e-002    -  1.00e+000 1.00e+000f  1\n",
      "  11 4.9267371e-006 0.00e+000 5.95e-002  -1.7 2.53e-002    -  1.00e+000 1.00e+000f  1\n",
      "  12 2.8189505e-009 0.00e+000 8.31e-004  -2.5 3.20e-003    -  1.00e+000 1.00e+000f  1\n",
      "  13 1.0095040e-015 0.00e+000 8.68e-007  -5.7 9.78e-005    -  1.00e+000 1.00e+000f  1\n",
      "  14 1.3288608e-028 0.00e+000 2.02e-013  -8.6 4.65e-008    -  1.00e+000 1.00e+000f  1\n",
      "\n",
      "Number of Iterations....: 14\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  1.3288608467480825e-028   1.3288608467480825e-028\n",
      "Dual infeasibility......:  2.0183854587685121e-013   2.0183854587685121e-013\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Overall NLP error.......:  2.0183854587685121e-013   2.0183854587685121e-013\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 36\n",
      "Number of objective gradient evaluations             = 15\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 14\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.010\n",
      "Total CPU secs in NLP function evaluations           =      0.001\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "x = 0.9999999999999899 y = 0.9999999999999792\n",
      "This is Ipopt version 3.12.2, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        2\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        1\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.3288608e-028 8.00e+000 1.56e-013  -1.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 5.0288811e+003 1.78e-015 1.04e+004  -1.0 5.34e+000    -  1.00e+000 1.00e+000h  1\n",
      "   2 2.9288883e+002 0.00e+000 2.25e+003  -1.0 7.07e-001    -  1.00e+000 1.00e+000f  1\n",
      "   3 5.6537755e+000 0.00e+000 2.04e+002  -1.0 2.30e-001    -  1.00e+000 1.00e+000f  1\n",
      "   4 2.8949941e+000 0.00e+000 2.39e+000  -1.0 2.55e-002    -  1.00e+000 1.00e+000f  1\n",
      "   5 2.8946076e+000 0.00e+000 3.43e-004  -1.0 3.07e-004    -  1.00e+000 1.00e+000f  1\n",
      "   6 2.8946076e+000 0.00e+000 7.87e-012  -5.7 4.42e-008    -  1.00e+000 1.00e+000f  1\n",
      "\n",
      "Number of Iterations....: 6\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  2.8946075504894604e+000   2.8946075504894604e+000\n",
      "Dual infeasibility......:  7.8660411517716966e-012   7.8660411517716966e-012\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Overall NLP error.......:  7.8660411517716966e-012   7.8660411517716966e-012\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 7\n",
      "Number of objective gradient evaluations             = 7\n",
      "Number of equality constraint evaluations            = 7\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 7\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 6\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.002\n",
      "Total CPU secs in NLP function evaluations           =      0.001\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "x = 2.7011471240982194 y = 7.2988528759017814\n"
     ]
    }
   ],
   "source": [
    "using JuMP,Ipopt\n",
    "m = Model(solver = IpoptSolver())\n",
    "@variable(m, x, start = 0.0)\n",
    "@variable(m, y, start = 0.0)\n",
    "\n",
    "@NLobjective(m, Min, (1-x)^2 + 100(y-x^2)^2)\n",
    "\n",
    "solve(m)\n",
    "println(\"x = \", getvalue(x), \" y = \", getvalue(y))\n",
    "\n",
    "# adding a (linear) constraint\n",
    "@constraint(m, x + y == 10)\n",
    "solve(m)\n",
    "println(\"x = \", getvalue(x), \" y = \", getvalue(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20Ã—20 Array{Float64,2}:\n",
       " -0.622234     1.73638e-8   7.90617e-9  â€¦   8.58784e-9   2.73281e-8\n",
       "  1.73638e-8  -0.231819     1.69905e-8      1.84549e-8   5.8726e-8 \n",
       "  7.90617e-9   1.69905e-8  -0.671033        8.40318e-9   2.67404e-8\n",
       "  1.08178e-8   2.32476e-8   1.05852e-8      1.14978e-8   3.65881e-8\n",
       "  8.51114e-9   1.82906e-8   8.32816e-9      9.04623e-9   2.87868e-8\n",
       "  8.60136e-9   1.8484e-8    8.41641e-9  â€¦   9.14182e-9   2.90904e-8\n",
       "  9.16301e-8   1.96899e-7   8.96594e-8      9.73822e-8   3.09872e-7\n",
       "  8.43536e-9   1.81278e-8   8.25401e-9      8.96568e-9   2.85305e-8\n",
       "  1.34564e-8   2.89177e-8   1.31671e-8      1.43022e-8   4.55118e-8\n",
       "  1.00337e-8   2.15626e-8   9.81798e-9      1.06645e-8   3.39363e-8\n",
       "  7.93194e-9   1.70457e-8   7.7614e-9   â€¦   8.43049e-9   2.68272e-8\n",
       "  9.94346e-9   2.13687e-8   9.72969e-9      1.05686e-8   3.36311e-8\n",
       "  5.35527e-8   1.15078e-7   5.2401e-8       5.69153e-8   1.81107e-7\n",
       "  1.65781e-8   3.56258e-8   1.62217e-8      1.76199e-8   5.60689e-8\n",
       "  4.02472e-8   8.64868e-8   3.93816e-8      4.27747e-8   1.36112e-7\n",
       "  6.06154e-8   1.30254e-7   5.93117e-8  â€¦   6.44212e-8   2.04991e-7\n",
       "  3.52884e-8   7.58314e-8   3.45296e-8      3.75047e-8   1.19343e-7\n",
       "  1.57144e-8   3.37698e-8   1.53765e-8      1.67019e-8   5.31479e-8\n",
       "  8.58784e-9   1.84549e-8   8.40318e-9     -0.840006     2.90447e-8\n",
       "  2.73281e-8   5.8726e-8    2.67404e-8      2.90447e-8  -0.144267  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Auto-differentiation with ForwardDiff in Julia\n",
    "using ForwardDiff\n",
    "h(x) = sin(x[1]) + x[1] * x[2] + sinh(x[1] * x[2]) #multivariate.\n",
    "x = [1.4 2.2]\n",
    "ForwardDiff.gradient(h,x) #uses AD, seeds from x\n",
    "\n",
    "#Or, can use complicated functions, \n",
    "f(x) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);\n",
    "g = (x) -> ForwardDiff.gradient(f, x); #New gradient function\n",
    "x2 = rand(20)\n",
    "g(x2) #gradient at a random 20 dim point\n",
    "ForwardDiff.hessian(f,x2) #Or the hessian\n",
    "\n",
    "#https://github.com/JuliaDiff/ReverseDiff.jl has more complicated setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
